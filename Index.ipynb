{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2889,"status":"ok","timestamp":1725923389071,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"dkm1adZgzpkh","outputId":"25db3934-2779-4cc6-9ab9-5792819da529"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1725923389072,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"ikV8idO-zuFX","outputId":"05c8d3c2-4ec0-408c-e380-bb575674134a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/flower-fgvc\n","common\t     data\t\tdatautils    Index.ipynb  models     run.yaml\n","config.yaml  data_processor.py\texperiments  index.py\t  README.md\n"]}],"source":["# move into project directory\n","repo_name = \"flower-fgvc\"\n","%cd /content/drive/MyDrive/Personal-Projects/$repo_name\n","!ls"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1725923389072,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"8u-0KeBez7WX","outputId":"905dc1a2-3eb4-4eac-d224-01990e71c2d5"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install matplotlib numpy pandas pyyaml opencv-python\\n'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# set up environment\n","# comment out if not required\n","'''\n","!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib numpy pandas pyyaml opencv-python\n","'''\n","\n","#!pip install transformers\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1725923389072,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"jDO9ey2Uz8Le"},"outputs":[],"source":["# this cell is for downloading data.\n","# as of yet data is not hosted and is available in the private data folder\n","\n","#!tar xf data/102flowers.tgz -C data/"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18088,"status":"ok","timestamp":1725923407155,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"VkNlM5sUzmsR"},"outputs":[],"source":["#set up some imports\n","\n","import numpy as np\n","import torch\n","import random\n","from torchvision import transforms\n","\n","# custom imports\n","\n","from common.utils import init_config, get_exp_params, get_modelinfo\n","from datautils.dataset import FlowerDataset\n","from datautils.datareader import get_file_paths\n","from experiments.classification import Classification\n","from common.visualization import Visualization\n","from experiments.classifier_tester import ModelTester\n","from models.custom_models import get_model"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1725923407156,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"JuknlEGUzmsU"},"outputs":[],"source":["seed = 123\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1725923407156,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"6OWsEeMBzmsU","outputId":"95eb0f8d-c1bf-4485-e3e2-4c2f00852006"},"outputs":[{"name":"stdout","output_type":"stream","text":["nb {'data_dir': '/content/drive/MyDrive/Personal-Projects/flower-fgvc/data', 'device': 'cpu', 'output_dir': '/content/drive/MyDrive/Personal-Projects/flower-fgvc/output', 'root_dir': '/content/drive/MyDrive/Personal-Projects/flower-fgvc', 'use_gpu': False}\n"]}],"source":["config_params = init_config()\n","print('nb', config_params)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1725923407156,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"fzHibw0hzmsW","outputId":"0616afef-2614-4952-8544-c2606c537498"},"outputs":[{"name":"stdout","output_type":"stream","text":["Experiment parameters\n","\n","{'transform': {'resize_dim': 399, 'crop_dim': 300}, 'train': {'batch_size': 64, 'loss': 'ecc', 'epoch_interval': 1, 'num_epochs': 10, 'lamda1': 0.01, 'lamda2': 1.2, 'enable_lr_decay': False, 'lr_step': 10, 'lr_decay': 0.1, 'ecc_alpha': 0.5, 'shared_space_numfeats': 4096}, 'model': {'name': 'resnet18', 'optimizer': 'Adam', 'lr': 1e-05, 'weight_decay': 1e-05, 'amsgrad': True, 'momentum': 0.8, 'build_on_pretrained': False, 'pretrained_filename': '/models/checkpoints/last_model.pt'}, 'dataset': {'size': 'subset'}}\n"]}],"source":["# read experiment params\n","\n","exp_params = get_exp_params()\n","print('Experiment parameters\\n')\n","print(exp_params)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1725923407341,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"tDJp0hsrzmsW","outputId":"4253a9e7-f76b-4ebe-c068-4c0c0ff65835"},"outputs":[{"name":"stdout","output_type":"stream","text":["Full train dataset length 1020\n","Subset train dataset length 306\n","\n","Full validation dataset length 1020\n","Subset validation dataset length 306\n","\n","Full test dataset length 6149\n","Subset test dataset length 184\n"]}],"source":["composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        #std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","\n","train_fns, val_fns, test_fns, _ = get_file_paths(config_params['data_dir'])\n","ftr_dataset = FlowerDataset(config_params['data_dir'], train_fns, composed_transforms)\n","val_dataset = FlowerDataset(config_params['data_dir'], val_fns, composed_transforms)\n","test_dataset = FlowerDataset(config_params['data_dir'], test_fns, composed_transforms)\n","sm_trlen = int(0.3 * len(ftr_dataset))\n","sm_telen = int(0.03 * len(test_dataset))\n","sm_vlen = int(0.3 * len(val_dataset))\n","\n","sm_ftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(sm_trlen)))\n","sm_val_dataset = torch.utils.data.Subset(val_dataset, list(range(sm_vlen)))\n","sm_test_dataset = torch.utils.data.Subset(test_dataset, list(range(sm_telen)))\n","\n","print('Full train dataset length', len(ftr_dataset))\n","print('Subset train dataset length', sm_trlen)\n","print('\\nFull validation dataset length', len(val_dataset))\n","print('Subset validation dataset length', sm_vlen)\n","print('\\nFull test dataset length', len(test_dataset))\n","print('Subset test dataset length', sm_telen)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1725923407342,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"9gHliD61pROC"},"outputs":[],"source":["\n","from models.custom_models import get_model\n","import torch\n","from common.utils import get_exp_params, get_config, save_experiment_output, save_model_helpers, save_model_chkpt, get_saved_model, get_modelinfo\n","from torch.utils.data import DataLoader, Subset\n","from tqdm import tqdm\n","import os\n","from common.loss_utils import ECCLoss\n","from transformers import CLIPProcessor, CLIPModel\n","from torch.optim.lr_scheduler import StepLR\n","\n","class Classification:\n","\n","    def __init__(self, train_dataset, val_dataset):\n","        cfg = get_config()\n","        self.data_dir = cfg['data_dir']\n","        self.root_dir = cfg['root_dir']\n","        self.train_dataset = train_dataset\n","        self.val_dataset = val_dataset\n","        #self.test_dataset = test_dataset\n","        self.exp_params = get_exp_params()\n","        self.model_params = self.exp_params['model']\n","        self.device = cfg['device']\n","        self.num_classes = 102\n","        self.lamda1 = self.exp_params['train']['lamda1']\n","        self.lamda2 = self.exp_params['train']['lamda2']\n","        self.dim = 0\n","        #self.data_transform = transforms\n","\n","    def __loss_fn(self, loss_name = 'cross-entropy'):\n","        if loss_name == 'cross-entropy':\n","            return torch.nn.CrossEntropyLoss()\n","        elif loss_name == 'mse':\n","            return torch.nn.MSELoss()\n","        elif loss_name == 'l1':\n","            return torch.nn.L1Loss()\n","        elif loss_name == 'ecc':\n","            loss_fn = ECCLoss(self.num_classes, self.dim)\n","            return loss_fn\n","        else:\n","            raise SystemExit(\"Error: no valid loss function name passed! Check run.yaml\")\n","\n","    def __save_model_checkpoint(self, model_state, chkpt_info, is_chkpoint = True):\n","        if is_chkpoint:\n","            save_experiment_output(model_state, chkpt_info, True)\n","        else:\n","            save_experiment_output(model_state, chkpt_info, False)\n","        #os.remove(os.path.join(self.root_dir, \"models/checkpoints/current_model.pt\"))\n","\n","    def __get_clip_features4classes(self):\n","        model_name = \"openai/clip-vit-base-patch32\"  # You can choose other available models\n","        num_text_feats = 512\n","        model = CLIPModel.from_pretrained(model_name)\n","        processor = CLIPProcessor.from_pretrained(model_name)\n","        lines = []\n","        with open(os.path.join(self.data_dir, 'processed_class_descriptions.txt')) as fp:\n","            lines = fp.readlines()\n","        text_features = torch.zeros(self.num_classes, num_text_feats)\n","        for i, line in enumerate(lines):\n","            desc = line.split(\" : \")[1]\n","            inputs = processor(text=desc, return_tensors=\"pt\", padding=True)\n","            with torch.no_grad():\n","                outputs = model.get_text_features(**inputs)\n","            outputs = outputs / outputs.norm(p = 2, dim = -1, keepdim = True)\n","            outputs = outputs.cpu()\n","            text_features[i] = outputs\n","        return text_features\n","\n","\n","\n","    def __conduct_training(self, model, optimizer, train_loader, val_loader,\n","        tr_len, val_len, model_info = None):\n","        num_epochs = self.exp_params['train']['num_epochs']\n","        epoch_interval = self.exp_params['train']['epoch_interval']\n","\n","        if model_info == None:\n","            trlosshistory, vallosshistory, valacchistory = [], [], []\n","            epoch_arr = list(range(0, num_epochs))\n","        else:\n","            trlosshistory = model_info['trlosshistory']\n","            vallosshistory = model_info['vallosshistory']\n","            valacchistory =  model_info['valacchistory']\n","            last_epoch = model_info['last_epoch']\n","            epoch_arr = list(range(last_epoch + 1, num_epochs))\n","\n","        self.text_features = self.__get_clip_features4classes().to(self.device)\n","        ce_loss_fn = self.__loss_fn()\n","        loss_fn = self.__loss_fn(self.exp_params['train']['loss'])\n","        #print('text features size', self.text_features.size(), '\\n')\n","        scheduler = StepLR(optimizer,\n","            step_size = self.exp_params['train']['lr_step'],\n","            gamma = self.exp_params['train']['lr_decay'])\n","\n","        for ei, epoch in enumerate(epoch_arr):\n","            model.train()\n","            tr_loss, val_loss, val_acc = 0.0, 0.0, 0.0\n","            ratio = (epoch + 1) / num_epochs\n","\n","            for _, batch in enumerate(tqdm(train_loader, desc = '\\t\\tRunning through training set', position = 0, leave = True, disable = True)):\n","                optimizer.zero_grad()\n","                imgs = batch['img'].float().to(self.device)\n","                olabels = batch['olabel'].to(self.device)\n","                lbls = batch['label'].type(torch.LongTensor).to(self.device)\n","                op,feats = model(imgs)\n","                #print('op sz', op.size(), olabels.size(), batch['label'].size(), feats.size())\n","                celoss = ce_loss_fn(op, lbls) * imgs.size(0)\n","                mcc, clg, _, _ = loss_fn(feats, op, lbls)\n","                loss = celoss + (ratio * self.lamda1 * mcc) + (ratio * self.lamda2 * clg)\n","                loss.backward()\n","                optimizer.step()\n","                tr_loss += loss.item()\n","            if self.exp_params['train']['enable_lr_decay']:\n","                scheduler.step()\n","\n","            tr_loss /= tr_len\n","            trlosshistory.append(tr_loss)\n","\n","            model.eval()\n","\n","            for _, batch in enumerate(tqdm(val_loader, desc = '\\t\\tRunning through validation set', position = 0, leave = True, disable = True)):\n","                imgs = batch['img'].float().to(self.device)\n","                olabels = batch['olabel'].to(self.device)\n","                lbls = batch['label'].type(torch.LongTensor).to(self.device)\n","                op, feats = model(imgs)\n","                celoss = ce_loss_fn(op, lbls) * imgs.size(0)\n","                mcc, clg, _, _ = loss_fn(feats, op, lbls)\n","                loss = celoss + (self.lamda1 * mcc * ratio) + (self.lamda2 * clg * ratio)\n","                #loss = loss_fn(op, olabels)\n","                val_loss += loss.item()\n","                pred_label = torch.argmax(op, 1)\n","                #print('label size', correct_label.size(), pred_label.size())\n","                val_acc += (lbls == pred_label).sum()\n","\n","            val_loss /= val_len\n","            val_acc /=  val_len\n","            vallosshistory.append(val_loss)\n","            valacchistory.append(val_acc.item())\n","\n","            if epoch % epoch_interval == 0 or ei == 0:\n","                print(f'\\tEpoch {epoch} Training Loss: {tr_loss}')\n","                print(f\"\\tEpoch {epoch} Validation Loss: {val_loss}\\n\")\n","\n","            model_info = {\n","                'trlosshistory': trlosshistory,\n","                'vallosshistory': vallosshistory,\n","                'valacchistory': valacchistory,\n","                'last_epoch': epoch\n","            }\n","\n","            self.__save_model_checkpoint(\n","                model,\n","                model_info\n","            )\n","\n","        model_info = {\n","            'trlosshistory': trlosshistory,\n","            'vallosshistory': vallosshistory,\n","            'valacchistory': valacchistory,\n","            'last_epoch': -1\n","        }\n","        self.__save_model_checkpoint(model, model_info)\n","\n","    def __get_model(self, model_name):\n","        model = get_model(102, model_name)\n","        model_chkpt_path = os.path.join(self.root_dir, 'models/checkpoints/curr_model.pt')\n","        print('model chkpt path', model_chkpt_path)\n","        if os.path.exists(model_chkpt_path):\n","            print('Loading saved model...')\n","            model = get_saved_model(model, True)\n","            model_info = get_modelinfo(True)\n","            return model, model_info\n","        return model, None\n","\n","\n","    def run_fgvc_pipeline(self):\n","        model_name = self.model_params['name']\n","        model, model_info = self.__get_model(model_name)\n","        self.dim = model.dim\n","        optimizer = torch.optim.Adam(model.parameters(),\n","            lr = self.model_params['lr'],\n","            weight_decay = self.model_params['weight_decay'],\n","            amsgrad = self.model_params['amsgrad'])\n","        batch_size = self.exp_params['train']['batch_size']\n","\n","        train_loader = DataLoader(self.train_dataset, batch_size = batch_size, shuffle = False)\n","        val_loader = DataLoader(self.val_dataset, batch_size = batch_size, shuffle = False)\n","        tr_len = len(self.train_dataset)\n","        val_len = len(self.val_dataset)\n","\n","        print('Training of classifier...\\n')\n","\n","        self.__conduct_training(model, optimizer, train_loader, val_loader, tr_len, val_len, model_info)\n","\n","        torch.cuda.empty_cache()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"X6RpmEbz94kl"},"outputs":[{"name":"stdout","output_type":"stream","text":["model chkpt path /content/drive/MyDrive/Personal-Projects/flower-fgvc/models/checkpoints/curr_model.pt\n","Loading saved model...\n"]},{"name":"stderr","output_type":"stream","text":["/content/drive/MyDrive/Personal-Projects/flower-fgvc/common/utils.py:115: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  return torch.load(model_path, map_location = torch.device(config_params[\"device\"]))\n"]},{"name":"stdout","output_type":"stream","text":["Training of classifier...\n","\n","\tEpoch 5 Training Loss: 5.074434118333206\n","\tEpoch 5 Validation Loss: 5.029408473594516\n","\n","\tEpoch 6 Training Loss: 4.977813770568448\n","\tEpoch 6 Validation Loss: 4.99332432965048\n","\n","\tEpoch 7 Training Loss: 4.878519095626532\n","\tEpoch 7 Validation Loss: 4.941398271548203\n","\n","\tEpoch 8 Training Loss: 4.780710357466554\n","\tEpoch 8 Validation Loss: 4.896917006548713\n","\n","\tEpoch 9 Training Loss: 4.686429989883323\n","\tEpoch 9 Validation Loss: 4.85555556552862\n","\n"]}],"source":["# cell that trains the model\n","composed_transforms =  transforms.Compose([\n","            #transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                        std=[0.229, 0.224, 0.225]),\n","            transforms.Resize(exp_params['transform']['resize_dim']),\n","            transforms.CenterCrop(exp_params['transform']['crop_dim'])\n","        ])\n","if exp_params['dataset']['size'] == 'subset':\n","    classification = Classification(sm_ftr_dataset, sm_val_dataset)\n","    classification.run_fgvc_pipeline()\n","else:\n","    classification = Classification(ftr_dataset, val_dataset)\n","    classification.run_fgvc_pipeline()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1725923695301,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"N2UK59kVjy0T"},"outputs":[],"source":["model_info = get_modelinfo('')\n","vis = Visualization(model_info)\n","vis.get_results()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1725923695301,"user":{"displayName":"Vinitra","userId":"09606499732062179579"},"user_tz":240},"id":"71AKIu2LSXjX"},"outputs":[],"source":["# cell that tests the model\n","model = get_model(102, exp_params[\"model\"][\"name\"])\n","model.load_state_dict(torch.load(\"models/checkpoints/last_model.pt\", map_location = torch.device(config_params[\"device\"])))\n","\n","if exp_params['dataset']['size'] == 'subset':\n","    mt = ModelTester(model, sm_test_dataset, composed_transforms)\n","    mt.test_and_plot()\n","else:\n","    mt = ModelTester(model, sm_test_dataset, composed_transforms)\n","    mt.test_and_plot()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}