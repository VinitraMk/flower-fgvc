{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up some imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# custom imports\n",
    "\n",
    "from common.utils import init_config, get_exp_params\n",
    "from datautils.dataset import FlowerDataset\n",
    "from datautils.datareader import get_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb {'data_dir': '/home/mikasaackerman/projects/ml-projects/flower-fgvc/data', 'device': 'cpu', 'output_dir': '/home/mikasaackerman/projects/ml-projects/flower-fgvc/output', 'root_dir': '/home/mikasaackerman/projects/ml-projects/flower-fgvc', 'use_gpu': False}\n"
     ]
    }
   ],
   "source": [
    "config_params = init_config()\n",
    "print('nb', config_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read experiment params\n",
    "\n",
    "exp_params = get_exp_params()\n",
    "print('Experiment parameters\\n')\n",
    "print(exp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mFlowerDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_dir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/ml-projects/flower-fgvc/datautils/FlowerDataset.py:13\u001b[0m, in \u001b[0;36mFlowerDataset.__init__\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m labels_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagelabels.mat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m labels_mat \u001b[38;5;241m=\u001b[39m loadmat(labels_path)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_mat\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_tensor)\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got dict)"
     ]
    }
   ],
   "source": [
    "train_fns, val_fns, test_fns, _ = get_file_paths(config_params['data_dir'])\n",
    "ftr_dataset = FlowerDataset(config_params['data_dir'], train_fns)\n",
    "val_dataset = FlowerDataset(config_params['data_dir'], val_fns)\n",
    "test_dataset = FlowerDataset(config_params['data_dir'], test_fns)\n",
    "sm_trlen = int(0.1 * len(ftr_dataset))\n",
    "sm_telen = int(0.01 * len(test_dataset))\n",
    "sm_vlen = int(0.1 * len(val_dataset))\n",
    "\n",
    "sm_ftr_dataset = torch.utils.data.Subset(ftr_dataset, list(range(sm_trlen)))\n",
    "sm_val_dataset = torch.utils.data.Subset(val_dataset, list(range(sm_vlen)))\n",
    "sm_test_dataset = torch.utils.data.Subset(test_dataset, list(range(sm_telen)))\n",
    "\n",
    "print('Full train dataset length', len(ftr_dataset))\n",
    "print('Subset train dataset length', sm_trlen)\n",
    "print('Full validation dataset length', len(val_dataset))\n",
    "print('Subset validation dataset length', sm_vlen)\n",
    "print('Full test dataset length', len(test_dataset))\n",
    "print('Subset test dataset length', sm_telen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlprojects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
